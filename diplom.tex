\documentclass[aps,%
12pt,%
final,%
oneside,
onecolumn,%
musixtex, %
superscriptaddress,%
centertags]{article} %%
\topmargin=-40pt
\textheight=650pt
\usepackage[english,russian]{babel}
\usepackage[utf8]{inputenc}
%всякие настройки по желанию%
\usepackage[colorlinks=true,linkcolor=blue,unicode=true]{hyperref}
\usepackage{euscript}
\usepackage{supertabular}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb, amsmath}
\usepackage{textcomp}
\usepackage[noend]{algorithmic}
\usepackage[ruled]{algorithm}
\selectlanguage{russian}

\begin{document}

\begin{titlepage}
\begin{center}
% Upper part of the page
\textbf{\Large САНКТ-ПЕТЕРБУРГСКИЙ \\ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ} \\[1.0cm]
\textbf{\large Математико-Механический факультет} \\[0.2cm]
\textbf{\large Кафедра информационно аналитических систем}\\[3.5cm]

% Title
\textbf{\LARGE Суммаризация групп в социальных сетях}\\[1.0cm]
\textbf{\Large Дипломная работа студента 645 группы} \\[0.2cm]
\textbf{\Large Чурикова Никиты Сергеевича} \\[3.5cm]

%supervisor
\begin{flushright} \large
\emph{Научный руководитель:} \\
к.ф. - м.н., доцент \textsc{Графеева Н. Г.}
\end{flushright}
 \begin{flushright} \large
\emph{Рецензент:} \\
Руководитель департамента вычислительной биологии \textsc{Яковлев П. А.}
\end{flushright}
\begin{flushright} \large
\emph{Заведующий кафедрой:} \\
к.ф. - м.н., доцент \textsc{Михайлова Е. Г.}
\end{flushright}
\vfill

% Bottom of the page
{\large {Санкт-Петербург}} \par
{\large {2019 г.}}
\end{center}
\end{titlepage}

% Table of contents
\tableofcontents

\section{Аннотация}
Одной из задач обработки естественного языка является задача суммаризации текста.
Ее целью является уменьшение размера исходного текста без потери ключевой информации.
В данной работе мы решаем схожую проблему, но для информационных ресурсов в социальных сетях.
В частности, необходимо рассмотреть задачу суммаризации текстов и картинок, поскольку
это два основных источника информации. В тексте мы приводим численное обоснование
выбранных методов, а также приводим оценку нашей суммаризации людьми.

\section{Введение}
В современном мире создается все больше и больше информации, которую мы можем потреблять.
Новости, статьи, юмор постоянно меняются и создаются людьми. При таком потоке информации
появляется потребность в инструментах, способных давать как можно больше информации
с минимальными потерями.

При чтении новостей люди, как правило, не идут дальше новостных заголовков \cite{jaysondemers2016},
для популярных технических статей создают краткие описания описывающие их достижения
и основные моменты \cite{tldr_arxiv2019, articleessence2019}, а визуальный контент нередко подчиняется единому шаблону.

В данной работе мы показываем, как используя современные достижения в области анализа
данных можно извлекать полезную информацию из новостных ресурсов в социальной сети вконтакте \cite{vk2019},
приводим оценки людей нашей системы и приводим сравнение с наивными решениями.

\subsection{Постановка задачи}
В данной работе мы решили остановиться на двух основных современных видах медиа: тексте и
изображениях. В данной работе мы не рассматриваем обработку видео, но есть предположения,
что предложенные идеи насчет изображений можно было бы распространить на видео-информацию.

Для текстовых ресурсов задача суммаризации была разбита на две подзадачи: 1) извлечение
ключевых слов, присущих данному источнику информации и 2) автоматическое создание заголовков.

Для изображений -- это сбор похожих изображений в кластера и показ некоторых
одних изображений, иллюстрирующих каждую группу.

Через извлечение данной информации мы хотим добиться эффекта "чтения по диагонали".
\subsection{Обзор литературы}
Рассказать про литературу, которая рассматривает задачи выше.
\subsection{Полученные результаты}
Что является результатом работы (будет веб сервис, куда можно закинуть ссылку на группу),
как оценивали качество (продолжить результаты работы алгоритмов толокерам), а также
оценка качества по автоматизированным метрикам, и как они коррелируют с оценками людей.
Сравниться с бэйзлайном.

\section{Алгоритмы, использованные в работе}
Нами были использованы как классические подходы, так и новые, основанные на нейронных сетях.
В следующих секциях мы опишем их основные принципы, а также приведем ссылки на их реализации.

\subsection{Суммаризация текста}
Для суммаризации текста мы воспользовались алгоритмом экстрактивной суммаризации
основанном на TextRank \cite{DBLP:journals/corr/BarriosLAW16, rehurek_lrec},
и моделью трансформера \cite{DBLP:journals/corr/VaswaniSPUJGKP17}, обученной на
датасете РИА новостей \cite{gavrilov2018self}.
Для предобработки данных модели трансформера мы использовали byte
pair encoding \cite{DBLP:journals/corr/SennrichHB15}.
Помимо этого мы извлекали первое предложение из новости.
Для TextRank и извлечения первого предложения не требуется обучающая выборка, что
делает их очень удобными в использовании. При этом, исследования показывают, что
в задаче генерации заголовков, первое предложение в новости --
это очень сильный бэйзлаин \cite{gavrilov2018self},
который трудно побить как экстрактивной, так и абстрактивной суммаризацией.

\subsection{Суммаризация изображений}
Для суммаризации изображений мы реализовали алгоритм,
описанный в статье \cite{DBLP:conf/icsipa/SharmaKASK15}.
Основная идея состоит в том, что из изображений извлекаются
признаки, инвариантные к поворотам \cite{Lowe:2004:DIF:993451.996342},
эти признаки кластеризуют
используя k-means \cite{Arthur:2007:KAC:1283383.1283494} и индексы кластеров
используют как признаки для латентного размещения
Дирихле \cite{Blei:2003:LDA:944919.944937, rehurek_lrec}.

Помимо этого, мы попробовали
на нашей задаче обучению метрике между изображениями
\cite{DBLP:journals/corr/abs-1803-11095, DBLP:journals/corr/abs-1810-06951}.

\subsection{Оценки качества}
Для оценки качества текстовых моделей мы использовали метрику ROUGE-L F1 \cite{Lin:2004},
при этом мы считали ее на датасете РИА новостей \cite{gavrilov2018self}.

Помимо этого, как для текстовых данных, так и для изображений, мы  использовали
Яндекс.Толоку \cite{yandex_toloka_2019}, чтобы привлечь людей к оценке качества наших результатов.

\section{Эксперименты}
Для обучения моделей были использованы 8 Tesla K80.

\section{Заключение}
На февраль 2019:

В данной работе мы ожидаем показать, что предложенные нами решения не хуже,
а даже лучше предложенных бэйзлайнов как по автоматическим оценкам, так и по оценкам
людей. Мы также представим код и ссылку на сервис, куда можно отправить ссылку на
интересующую группу и оценить получившийся результат. Мы также планируем показать
результаты в "одноклассниках" и рассказать об их мнении насчет полученного решения,
поскольку год назад предлагалось совместное сотрудничество над данной проблемой.

\bibliographystyle{gost780s}
\bibliography{test}

\end{document}
