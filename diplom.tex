\documentclass[aps,%
12pt,%
final,%
oneside,
onecolumn,%
musixtex, %
superscriptaddress,%
centertags]{article} %%
\topmargin=-40pt
\textheight=650pt
\usepackage[english,russian]{babel}
\usepackage[utf8]{inputenc}
%всякие настройки по желанию%
\usepackage[colorlinks=true,linkcolor=blue,unicode=true]{hyperref}
\usepackage{euscript}
\usepackage{supertabular}
\usepackage[pdftex]{graphicx}
\usepackage{amsthm,amssymb, amsmath}
\usepackage{textcomp}
\usepackage[noend]{algorithmic}
\usepackage[ruled]{algorithm}
\selectlanguage{russian}

\begin{document}

\begin{titlepage}
\begin{center}
% Upper part of the page
\textbf{\Large САНКТ-ПЕТЕРБУРГСКИЙ \\ ГОСУДАРСТВЕННЫЙ УНИВЕРСИТЕТ} \\[1.0cm]
\textbf{\large Математико-Механический факультет} \\[0.2cm]
\textbf{\large Кафедра информационно аналитических систем}\\[3.5cm]

% Title
\textbf{\LARGE Суммаризация групп в социальных сетях}\\[1.0cm]
\textbf{\Large Дипломная работа студента 645 группы} \\[0.2cm]
\textbf{\Large Чурикова Никиты Сергеевича} \\[3.5cm]

%supervisor
\begin{flushright} \large
\emph{Научный руководитель:} \\
к.ф. - м.н., доцент \textsc{Графеева Н. Г.}
\end{flushright}
 \begin{flushright} \large
\emph{Рецензент:} \\
Руководитель департамента вычислительной биологии \textsc{Яковлев П. А.}
\end{flushright}
\begin{flushright} \large
\emph{Заведующий кафедрой:} \\
к.ф. - м.н., доцент \textsc{Михайлова Е. Г.}
\end{flushright}
\vfill

% Bottom of the page
{\large {Санкт-Петербург}} \par
{\large {2019 г.}}
\end{center}
\end{titlepage}

% Table of contents
\tableofcontents

\section{Аннотация}
Одной из задач обработки естественного языка является задача суммаризации текста.
Ее целью является уменьшение размера исходного текста без потери ключевой информации.
В данной работе мы решаем схожую проблему, но для информационных ресурсов в социальных сетях.
В частности, необходимо рассмотреть задачу суммаризации текстов и картинок, поскольку
это два основных источника информации. В тексте мы приводим численное обоснование
выбранных методов, а также приводим оценку нашей суммаризации людьми.

\section{Введение}
В современном мире создается все больше и больше информации, которую мы можем потреблять.
Новости, статьи, юмор постоянно меняются и создаются людьми. При таком потоке информации
появляется потребность в инструментах, способных давать как можно больше информации
с минимальными потерями.

При чтении новостей люди, как правило, не идут дальше новостных заголовков \cite{jaysondemers2016},
для популярных технических статей создают краткие описания описывающие их достижения
и основные моменты \cite{tldr_arxiv2019, articleessence2019}, а визуальный контент нередко подчиняется единому шаблону.

В данной работе мы показываем, как используя современные достижения в области анализа
данных можно извлекать полезную информацию из новостных ресурсов в социальной сети вконтакте \cite{vk2019},
и приводим обоснование выбора решений, основываясь на соответствующих метриках.

\subsection{Постановка задачи}
Мы поставили перед собой задачу создать систему, которой бы можно было передавать ссылку на новостной ресурс в социальной сети вконтакте, а на выходе получать его краткое описание. В рамках работы мы ограничились новостными ресурсами с высоким содержанием текста.

На Рис. \ref{app_story} мы показываем как работает наше решение "с высоты птичьего полета". Процесс имеет следующий вид, мы получаем ссылку на группу ВК, затем через API вконтакте получаем информацию о группе и оцениваем количество текста в ней. если содержание текста низкое, то мы говорим, что это ресурс с доминирующим медиа-контентом, если в группе мало предложений, но достаточно слов, то решается задача выделения ключевых слов, если в группе высокое содержание предложений, то мы решаем задачу генерации заголовков.

Таким образом, с алгоритмической точки зрения, задача суммаризации новостного ресурса была рассмотрена нами как две подзадачи:
\begin{enumerate}
  \item Извлечение ключевых слов, присущих данному источнику информации;
  \item Сжатие новостей, используя автоматическое создание заголовков.
\end{enumerate}

Через извлечение данной информации мы хотим добиться эффекта "чтения по диагонали".

Для оценки качества наших алгоритмов, мы воспользовались открытыми датасетами для генерации заголовков и извлечению ключевых слов.

\begin{figure}[ht]
\begin{center}

\scalebox{0.6}{
   \includegraphics{images/app_story.png}
}

\caption{
\label{app_story} Принцип работы системы.
        }
\end {center}
\end {figure}

\subsection{Обзор литературы}
Задача сжатия текста с малой потерей смысла и сохранением возможности его прочтения
имеет название задачи \textit{суммаризации}. При этом, есть два концептуальных подхода к решению:
экстрактивный, когда для создания краткого содержания извлекаются целые куски текста вплоть до предложений,
и абстрактивная, где в кратком содержании могут быть слова, которых не было в исходном тексте.

В частности, при исследовании абстрактивной генерации заголовков, мы отталкивались от статьи Вконтакте, посвященной данной проблеме \cite{gavrilov2018self}. Ими предлагается применять нейронные сети с архитектурой Transformer и предобработкой Byte pair encoding (BPE) \cite{DBLP:journals/corr/SennrichHB15}. Однако в задаче абстрактивной генерации заголовков существуют дебаты на тему того, что использовать в качестве входа модели. Поскольку долгое время SOTA были модели с архитектурой encoder decoder, то было невозможно использовать длинные входные последовательности. Потому авторы статьи \cite{Putra2018IncorporatingTS} исследуют различные подходы по предварительному извлечению "Topic sentence", которое нейронная сеть должна дальше обработать. Это предложение, как говорят авторы, в идеальном случае, должна отвечать на 5W1H. Но достаточно ответов на "что, кто, когда".

Для экстрактивной суммаризации чаще всего используют алгоритм TextRank \cite{TextrankOriginal}.
% TODO: Add more desctiption


% \subsection{Полученные результаты}
% Что является результатом работы (будет веб сервис, куда можно закинуть ссылку на группу),
% как оценивали качество (продолжить результаты работы алгоритмов толокерам), а также
% оценка качества по автоматизированным метрикам, и как они коррелируют с оценками людей.
% Сравниться с бэйзлайном.

\section{Алгоритмы, использованные в работе}
Нами были использованы как классические подходы, так и новые, основанные на нейронных сетях.
В следующих секциях мы опишем их основные принципы, а также приведем ссылки на их реализации.

\subsection{Суммаризация текста}
Для суммаризации текста мы воспользовались алгоритмом экстрактивной суммаризации
основанном на TextRank \cite{DBLP:journals/corr/BarriosLAW16, rehurek_lrec, TextrankOriginal},
и моделью трансформера \cite{DBLP:journals/corr/VaswaniSPUJGKP17}, обученной на
датасете РИА новостей \cite{gavrilov2018self}.
Для предобработки данных модели трансформера мы использовали byte
pair encoding \cite{DBLP:journals/corr/SennrichHB15}.
Помимо этого мы извлекали первое предложение из новости.
Для TextRank и извлечения первого предложения не требуется обучающая выборка, что
делает их очень удобными в использовании. При этом, исследования показывают, что
в задаче генерации заголовков, первое предложение в новости --
это очень сильный бэйзлаин \cite{gavrilov2018self},
который трудно побить как экстрактивной, так и абстрактивной суммаризацией.

\subsubsection{Baseline}

В качестве бэйзлаина в задаче генерации заголовков используется первое предложение новости. Именно им мы и воспользовались и отталкивались от него.


\subsubsection{TextRank}

TextRank является является адаптацией идеи алгоритма PageRank \cite{Page98thepagerank} с задачи рекомендации страниц в интернете на задачу рекомендации лучшего предложения или набора слов в тексте. Сам алгоритм состоит в том, что мы текст превращаем в граф, где узлы -- это предложения, а для каждого ребра подсчитывается вес, где вес определяется по количеству совпавших слов в двух предложениях.

Таким образом, получается, что можно выбрать предложение с самыми тяжелыми ребрами в качестве предложения, которое описывало бы исходный текст.

\begin{figure}[ht]
\begin{center}

\scalebox{0.4}{
   \includegraphics{images/text_rank_example_graph.png}
}

\caption{
\label{text_rank_example_graph}
        Пример результирующего графа textrank.}
\end {center}
\end {figure}

\subsubsection{Byte pair encoding}

Мы используем byte pair encoding (BPE), технику, предложенную Сеннрич для задачи машинного перевода в \cite{DBLP:journals/corr/SennrichHB15}. BPE -- это метод сжатия данных, в котором часто встречающиеся пары байтов заменяются дополнительными символами алфавита. В случае текстов, как в области машинного перевода, наиболее часто встречающиеся слова сохраняются в словаре, а менее часто встречающиеся слова заменяются последовательностью (обычно двумя) токенами. Например, для морфологически богатых языков окончания слов могут быть отделены, поскольку каждая форма слова определенно реже, чем ее основа. Кодирование BPE позволяет нам представлять все слова, включая те, что не встречаются по время обучения, с фиксированным словарным запасом.

\subsubsection{Universal transformer network}
В то время как рекуррентные нейронные сети могут быть легко использованы для определения модели Encoder-Decoder, тренировка таких моделей очень дорого с точки зрения вычислений. Другой недостаток состоит в том, что они используют только локальную информацию, опуская последовательность скрытых состояний H = {h1, ..., hN}. То есть любые два вектора из скрытого состояния hi и hj связаны с вычислениями j - i RNN, что затрудняет улавливание всех зависимостей в них из-за ограниченной емкости. Чтобы обучить богатую модель, которая изучила бы сложную текстовую структуру, мы должны определить модель, которая опирается на нелокальные зависимости в данных.
В этой работе мы принимаем архитектуру модели Universal Transformer \cite{}, которая является модифицированной версией Transformer \cite{}. Этот подход имеет несколько преимуществ по сравнению с RNN. Прежде всего, его можно тренировать параллельно. Кроме того, все входные векторы связаны друг с другом через механизм Attention. Это подразумевает, что архитектура Transformer учитывает нелокальные зависимости между токенами независимо от расстояния между ними, и, таким образом, она может выучить более сложное представление текста в статье, что оказывается необходимым для эффективного решения задачи суммаризации.

\subsection{Выделение ключевых слов}

Обзорная статья Сайдула и Ына \cite{hasan2014automatic} рассматривает наиболее сильные подходы к выделению ключевых слов.
Конкретно, они показывают для каких задач доходят какие алгоритмы. Основная таблица этой статьи приведена на таблице \ref{keywords_extraction_report},
и она говорит о том, какие алгоритмы показывают лучшие результаты на каких задачах.

Для данной работы мы реализовали TopicRank и TextRank и выложили эти реализации в качестве библиотеки на python \footnote{https://github.com/kuparez/keyverbum}, реализовав интерфейсы библиотеки Scikit-Learn \cite{scikit-learn, sklearn_api}.

\begin{table}[ht]
  \begin{center}
    \begin{tabular}{|l|l|l|l|l|}
      \hline
      \textbf{Dataset} & \textbf{Approach and System} & \textbf{P} & \textbf{R} & \textbf{F} \\ \hline
      Абстракты & TopicRank & 35.0 & 66.0 & 45.7 \\ \hline
      Блоги & CommunityCluster & 35.1 & 61.5 & 44.7 \\ \hline
      Новости & \begin{tabular}[c]{@{}l@{}} TextRank \end{tabular} & 28.8 & 35.4 & 31.7 \\ \hline
      Научные статьи & \begin{tabular}[c]{@{}l@{}}Statistical, semantic, \\ and distributional features\end{tabular} & 27.2 & 27.8 & 27.5 \\ \hline
    \end{tabular}
    \caption{
      \label{keywords_extraction_report} Sate of the art результаты извлечения ключевых слов на классических датасетах. P -- точность, R -- полнота, F -- среднее гармоническое точности и полноты.
    }
  \end{center}
\end{table}

В секциях ниже мы опишем детали наших реализаций данных алгоритмов.

\subsubsection{TopicRank}
TopicRank - это метод обучения без учителя, целью которого является извлечение ключевых фраз из наиболее важных тем документа. Темы определяются как кластеры похожих ключевых фраз-кандидатов. Извлечение ключевых фраз из документа состоит из следующих шагов, показанных на рисунке \ref{topicrank}. Во-первых, документ предварительно обрабатывается (сегментация предложений, разметка слов и тегирование частей речи), а кандидаты в ключевые фразы группируются по темам. Затем темы ранжируются в соответствии с их важностью в документе, и ключевые фразы извлекаются путем выбора одного кандидата ключевой фразы для каждой из наиболее важных тем.

\begin{figure}[ht]
\begin{center}

\scalebox{0.4}{
   \includegraphics{images/how_topicrank_works.png}
}

\caption{
\label{topicrank}
        Принцип работы TopicRank.}
\end {center}
\end {figure}

% \subsection{Суммаризация изображений}
% Для суммаризации изображений мы реализовали алгоритм,
% описанный в статье \cite{DBLP:conf/icsipa/SharmaKASK15}.
% Основная идея состоит в том, что из изображений извлекаются
% признаки, инвариантные к поворотам \cite{Lowe:2004:DIF:993451.996342},
% эти признаки кластеризуют
% используя k-means \cite{Arthur:2007:KAC:1283383.1283494} и индексы кластеров
% используют как признаки для латентного размещения
% Дирихле \cite{Blei:2003:LDA:944919.944937, rehurek_lrec}.
%
% Помимо этого, мы попробовали
% на нашей задаче обучению метрике между изображениями
% \cite{DBLP:journals/corr/abs-1803-11095, DBLP:journals/corr/abs-1810-06951}.

\subsection{Оценки качества}
Для оценки качества текстовых моделей мы использовали метрику ROUGE-L F1 \cite{Lin:2004},
при этом мы считали ее на датасете РИА новостей \cite{gavrilov2018self}. Помимо этого,
на основе этого датасета проводилось соревнование по генерации заголовков, где автором было
получено 3 место, а описание результатов соревнования было подано в качестве статьи на конференцию
"Диалог".

% Помимо этого, как для текстовых данных, так и для изображений, мы  использовали
% Яндекс.Толоку \cite{yandex_toloka_2019}, чтобы привлечь людей к оценке качества наших результатов.

\section{Анализ использованных данных}
% Рассказать про датасет Риа новостей и данные из ВК.

В работе были использованы несколько датасетов с целью выбора алгоритмов под соответствующие задачи.
В частности, мы воспользовались датасетом оценки качества выделения ключевых слов \cite{mannefedov2019}, недавно
опубликованным датасетом Риа новостей \cite{gavrilov2018self}, а также в нашей работе мы используем
данные из 25 групп вконтакте с разным целевым материалом: от медиа контента до полноценных длинных
текстов.

\subsection{Данные выделения ключевых слов}
Для анализа качества использованных алгоритмов для выделения ключевых слов
мы воспользовались датасетом с разнообразными статьями на русском языке \cite{mannefedov2019}.
В наборе присутствуют научные статьи из "журнала киберленика" \cite{cyberlenica},
технического блога "хабрахабр" \cite{habr} и новостных ресурсов "Независимая газета" \cite{independentjournal} и "Россия сегодня" \cite{rt}.

Таким образом, мы приводим русскоязычные аналоги всем англоязычным ресурсам из таблицы \ref{keywords_extraction_report}.


\section{}
For all experiments, we used the preprocessing as described above. For training of our models we used 8 Nvidia K80.

\subsection{Evaluation}
It is common practice to use ROUGE score \cite{Lin:2004} in summarization problems. In practice, so-called ROUGE 1,2, L - precision, recall, F1 metrics are being used. The names in ROUGE X - Y denote the following: X is the number of ngramm used to calculate the Y metric. In the case of ngramm of size L, the longest common subsequence from predicted sequence found in original sequence. Y metrics are classic accuracy, recall and F1 score.

In the competition, for the calculation of quality, the average of ROUGE 1, 2, L - F1 score was used.

\subsection{First sentence}

As described in \cite{Putra2018IncorporatingTS}, the first sentence for automatically creating a news headline is a very strong baseline. In particular, in the headline generation competition, the first sentence of news articles was proposed as a baseline solution.

However, we used our knowledge about the data and besides removal of html tags and entities we've also skipped first sentences with "риа новости" in it. This allowed us to skip sentences with information about the date the news was posted as these sentences did not contain any information besides that.

\subsection{Textrank}

We used the classic extractive summarization algorithm - textrank \cite{DBLP:journals/corr/BarriosLAW16}. We took implementation of this algorithm from gensim \cite{rehurek_lrec} To create a summary using keywords and original sentences we've set extraction size to be 20\% of the original text.

\subsection{Transformer}

Since the competition was held for only a month, we've decided to repeat the results described in the article VKontakte \cite{gavrilov2018self}. We took the implementation of the transformer from Open NMT, with the parameters described in the article.

Then, we tried to focus on what to use as input for the model. We tried the first sentence according to the rules above. We've also tried as an input first 2000 BPE tokens.

Due to restrictions on VK servers we could not make very complex predictions. There for, during predictions on leaderboard we've used beam search of size 5. But for evaluation on our test set we used beam size of 10.

\section{Results}

As could be seen in Table 1, none of the models we've trained could show better results than the preprocessed first sentence. Unfortunately, we could not check some of our models on VK servers due to the restrictions on time complexity of our models. For this reason, we also present results on our test set.

\begin{table}[htbp]
  \small
  \centering
  \begin{tabular}{|l|l|}
    \hline
    Algorithm                                                                                            & Score      \\ \hline
    Baseline                                                                                             & 0.19500071 \\ \hline
    First sentence                                                                                       & 0.19502427 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Wiki BPE transformer (first sentence, no beam search=5)\end{tabular} & 0.16397515 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Ria BPE transformer (2000 first tokens, beam search=5)\end{tabular}  & 0.16131584 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Textrank summarization\end{tabular}                                    & 0.10764881 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Textrank keywords\end{tabular}                                          & 0.06259589 \\ \hline
  \end{tabular}
  \caption{Results from evaluation by VK servers. Score is mean of ROUGE-1,2,L F1 score.}
\end{table}

Table 2 show results of evaluation on our test set. Surprisingly, we've got much better results on our split, than on public leaderboard. And specifically, neural networks perform much better than first sentence model. It's worth pointing out that transformer trained with RIA BPE perform slightly worse than transformer with Wiki BPE. We think, the reason for that might be that model is more robust, because it doesn't need to predict any variation of numbers, because all numeric data is reduced to zeros. Unfortunately, taxtrank based model didn't show good results for F1 score, but recall is pretty high. It's probably due to extraction of too much information.

Another thing is that local evaluation show better results than VK server evaluation. So we decided to check for data leaks. We assumed that there could be none, because for train\/test split we used scikit learn \cite{scikit-learn} train test split method. We checked, how many texts in our test set are identical to texts in train. It turned out that 975 texts in test set were found in train set.

Then we decided to check original data and find how many training examples are identical. We found, that 2651 texts are identical.

\begin{table}[htbp]
  \small
  \centering
  \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
    \hline
    Algorithm\textbackslash{}Score                                                             & 1F   & 1P   & 1R   & 2F   & 2P   & 2R   & LF   & LP   & LR   \\ \hline
    First sentence                                                                             & 0.23 & 0.16 & 0.44 & 0.10 & 0.07 & 0.21 & 0.16 & 0.15 & 0.40 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Wiki BPE transformer\\ (first sentence, beam=10)\end{tabular}& 0.37 & 0.39 & 0.36 & 0.20 & 0.21 & 0.19 & 0.34 & 0.37 & 0.34 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Wiki BPE transformer\\ (first sentence, beam=5)\end{tabular} & 0.39 & 0.41 & 0.39 & 0.22 & 0.23 & 0.22 & 0.37 & 0.39 & 0.37 \\ \hline
    % \begin{tabular}[c]{@{}l@{}}Wiki BPE \\ transformer\\ (first sentence, beam=1)\end{tabular} & 0.37 & 0.37 & 0.37 & 0.20 & 0.20 & 0.20 & 0.34 & 0.36 & 0.35 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Ria BPE transformer\\ (2000 first tokens)\end{tabular}       & 0.36 & 0.37 & 0.35 & 0.18 & 0.20 & 0.18 & 0.33 & 0.36 & 0.33 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Textrank summarization\end{tabular}                          & 0.14 & 0.09 & 0.41 & 0.05 & 0.03 & 0.17 & 0.09 & 0.08 & 0.38 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Textrank keywords\end{tabular}                                & 0.09 & 0.07 & 0.18 & 0.00 & 0.00 & 0.01 & 0.05 & 0.05 & 0.14 \\ \hline
    \end{tabular}
  \caption{ROUGE-1,2,F1, precision and recall scores.}
\end{table}

After our discovery of a leak in our test set distribution, we decided to check performance of our best abstractive summarization model, transformer with Wikipedia BPE with beam search equal to 5 on dataset with train set leak removed.

\begin{table}[htbp]
  \centering
  \small
  \begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
    \hline
    Algorithm\textbackslash{}Score                                                             & 1F   & 1P   & 1R   & 2F   & 2P   & 2R   & LF   & LP   & LR   \\ \hline
    \begin{tabular}[c]{@{}l@{}}Wiki BPE transformer\\ (first sentence, beam=5 with leak)\end{tabular} & 0.39 & 0.41 & 0.39 & 0.22 & 0.23 & 0.22 & 0.37 & 0.39 & 0.37 \\ \hline
    \begin{tabular}[c]{@{}l@{}}Wiki BPE transformer\\ (first sentence, beam=5 no leak)\end{tabular} & 0.39 & 0.40 & 0.39 & 0.22 & 0.23 & 0.22 & 0.36 & 0.38 & 0.37 \\ \hline
    \end{tabular}
  \caption{Model evaluation without leak}
\end{table}

As expected, model performed slightly worse, but still pretty good, so it's still hard to tell, why there is such a great difference between results on out test set and evaluation results from competition servers.

\begin{table}[htbp]
\scriptsize
\centering
\begin{tabular}{|l|l|}
\hline
Score & Example \\ \hline
0.00 & \begin{tabular}[c]{@{}l@{}}\textbf{Text}: 8 декабря 1991 года россия, белоруссия и украина подписали соглашение\\о создании содружества независимых государств (снг).\\ \textbf{Ground truth}: встреча в беловежской пуще\\ \textbf{Prediction}: заявил\end{tabular} \\ \hline
0.00 & \begin{tabular}[c]{@{}l@{}}\textbf{Text}: более 70 международных художников и арт-групп примут участие в основном\\проекте "больше света" \\ 5-й московской биеннале современного искусства,который будет показан в цвз "манеж" \\ с 20 сентября по 20 октября, сообщили риа новости в пресс-службе проекта.\\ \textbf{Ground truth}: стали известны все участники основного проекта\\5-й московской биеннале\\ \textbf{Prediction}: более 00 художников представят проект "больше света" в "манеже"\end{tabular} \\ \hline
0.99 & \begin{tabular}[c]{@{}l@{}}\textbf{Text}: фонд "сколково" и корпорация intel подписали в четверг соглашение\\о сотрудничестве, передает корреспондент риа новости.\\ \textbf{Ground truth}: "сколково" и intel подписали соглашение о сотрудничестве\\ \textbf{Prediction}: "сколково" и intel подписали соглашение о сотрудничестве\end{tabular} \\ \hline
\end{tabular}
\caption{Worse and best model performances. Score is mean of ROUGE-1,2,L F1 score.}
\end{table}

In table 4,the mean of ROUGE-1,2, L F1 is used as the score. In the table, we present two of the worst headline options that Wiki transformer can produce on data without a train leak in test.

\section{Заключение}

В данной работе мы предложили решение задачи краткого описания новостного ресурса. Решение включает в себя путь того, как с этой системой будет взаимодействовать пользователь, техническую архитектуру системы, обоснование выбранных алгоритмов, отталкиваясь от соответствующих решаемых подзадач.

Как результат, с алгоритмической точки зрения, система была разбита на две подзадачи: выделения ключевых слов и генерации заголовков. Нами были предложены лучшие алгоритмы, для решения соответствующих задач. В работе не был покрыт графический материал ввиду того, это является отдельным большим исследованием, при этом в этой работе мы заложили фундамент для дальнейших исследований в этой области, предоставив интерфейс для разработчиков и людей.

\section{Литература}

\bibliographystyle{gost780s}
\bibliography{test}

\end{document}
